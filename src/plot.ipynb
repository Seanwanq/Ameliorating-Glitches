{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../Mock_Data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_length = len(data)\n",
    "data_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn on the pyplot interaction mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# ax.plot(x, data[:,0], label='SNR')\n",
    "# ax.plot(x, data[:,1], label='Chisq')\n",
    "# ax.plot(x, data[:,2], label='Mass1')\n",
    "# ax.plot(x, data[:,3], label='Mass2')\n",
    "# ax.plot(x, data[:,4], label='Spin1z')\n",
    "# ax.plot(x, data[:,5], label='Spin2z')\n",
    "# ax.plot(x, data[:,6], label='Class')\n",
    "\n",
    "x = np.log(data[:,2])\n",
    "y = np.log(data[:,3])\n",
    "snr = np.log(data[:,0])\n",
    "\n",
    "ax.scatter(x,y,s=snr)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H1_O3a = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_H1_O3b = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_L1_O3a = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_L1_O3b = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_V1_O3a = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_V1_O3b = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_a = np.load(\"../data/dataset_all_H1_bootstrap_O3a.npy\")\n",
    "data_b = np.load(\"../data/dataset_all_H1_bootstrap_O3b.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = np.vstack([data_a,data_b])\n",
    "len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(total)\n",
    "pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(total)\n",
    "data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_length = int(data_length * 0.7)\n",
    "validating_set_length = int(data_length * 0.2)\n",
    "testing_set_length = data_length - training_set_length - validating_set_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = total[0:training_set_length,:]\n",
    "validating_set = total[training_set_length:training_set_length + validating_set_length,:]\n",
    "testing_set = total[training_set_length + validating_set_length:,:]\n",
    "\n",
    "len(training_set) + len(validating_set) + len(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_A = training_set[:,0:6]\n",
    "training_set_B = training_set[:,6]\n",
    "input_tensor = torch.tensor(training_set_A, dtype=torch.float32).to(device)\n",
    "label_tensor = torch.tensor(training_set_B, dtype=torch.int64).to(device)\n",
    "\n",
    "input_val_tensor = torch.tensor(validating_set[:,0:6], dtype=torch.float32).to(device)\n",
    "label_val_tensor = torch.tensor(validating_set[:,6], dtype=torch.int64).to(device)\n",
    "\n",
    "input_test_tensor = torch.tensor(testing_set[:,0:6], dtype=torch.float32).to(device)\n",
    "label_test_tensor = torch.tensor(testing_set[:,6], dtype=torch.int64).to(device)\n",
    "\n",
    "dataset = TensorDataset(input_tensor, label_tensor)\n",
    "dataset_val = TensorDataset(input_val_tensor, label_val_tensor)\n",
    "dataset_test = TensorDataset(input_test_tensor, label_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\seanw\\source_code\\Ameliorating-Glitches\\src\\plot.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/seanw/source_code/Ameliorating-Glitches/src/plot.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m(model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 128)\n",
    "        self.fc2 = nn.Linear(128,256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ...: 100%|██████████| 1000/1000 [1:10:54<00:00,  4.25s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1000), desc=\"Training ...\"):\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8410714285714286\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70      2160\n",
      "           1       0.90      0.90      0.90      2207\n",
      "           2       0.90      0.96      0.93      2183\n",
      "           3       0.96      0.42      0.58      2172\n",
      "           4       0.93      0.98      0.96      2110\n",
      "           5       0.85      0.80      0.83      2137\n",
      "           6       0.96      0.96      0.96      2151\n",
      "\n",
      "    accuracy                           0.84     15120\n",
      "   macro avg       0.87      0.84      0.84     15120\n",
      "weighted avg       0.87      0.84      0.84     15120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1903   18   39   21   55   87   37]\n",
      " [  58 1977   57    1   13  100    1]\n",
      " [  10   21 2086    2   54    4    6]\n",
      " [1109   13   12  906    7  101   24]\n",
      " [   7    0   32    0 2061    0   10]\n",
      " [ 215  169   15   11    3 1720    4]\n",
      " [   0    0   75    0   12    0 2064]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"../models/model2312082058local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(\"../models/model2312082058local\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
